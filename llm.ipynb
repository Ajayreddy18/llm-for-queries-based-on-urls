{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ec26f10-099b-45cf-b31a-c66a3aa73ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import streamlit as st\n",
    "import pickle\n",
    "import time\n",
    "import langchain\n",
    "from langchain import OpenAI\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.chains.qa_with_sources.loading import load_qa_with_sources_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea00d64-ae9e-4ae5-8ecf-86edbe446fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load your openai key\n",
    "os.environ['OPENAI_API_KEY'] = 'your openapi key here'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362d0b31-ab51-4439-840f-13b141c45860",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=OpenAI(temperature=0.9,max_tokens=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191588df-bc71-4385-bb00-98158c1326ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data\n",
    "loaders=UnstructuredURLLoader(urls=[\n",
    "    \"add your urls\"])\n",
    "data=loaders.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adb9ffb-2d27-481c-adc3-4c668c696d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now split the data into chunks\n",
    "splitting_text=RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000)\n",
    "docs=splitting_text.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385f0db2-6f3c-4522-aced-bf8637f4de19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create embeddings for these chunks and save them to FAISS index\n",
    "embeddings=OpenAIEmbeddings()\n",
    "#passing the documents to create FAISS vector index\n",
    "vectorindex_openai=FAISS.from_documents(docs,embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39e01c7-8991-49af-86f9-8a4a6964b71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing the vector index in local\n",
    "file_path=\"your_file_path.pkl\"\n",
    "with open(file_path,\"wb\") as f:\n",
    "    pickle.dump(vectorindex_openai,f)\n",
    "    \n",
    "if os.path.exists(file_path):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        vectorIndex = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f546d138-1f61-4095-943d-46d5de4367bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve similar embeddings for a given question and call LLM to retrieve final answer\n",
    "chain = RetrievalQAWithSourcesChain.from_llm(llm=llm, retriever=vectorIndex.as_retriever())\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6161e7-8627-406f-be30-65e9369cbdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to find the answer for a query\n",
    "query = \"asking a question from the specified urls to retrieve the answer \"\n",
    "\n",
    "\n",
    "langchain.debug=True\n",
    "\n",
    "chain({\"question\": query}, return_only_outputs=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
